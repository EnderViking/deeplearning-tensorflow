{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>多层神经网络</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "gpu_no = '0'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu_no\n",
    "# 定义TensorFlow配置\n",
    "config = tf.ConfigProto()\n",
    "# 配置GPU内存分配方式，按需增长，很关键\n",
    "config.gpu_options.allow_growth = True\n",
    "# 配置可使用的显存比例\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.1\n",
    "# 在创建session的时候把config作为参数传进去\n",
    "sess = tf.Session(config = config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 使用隐藏层解决非线性问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(dtype=tf.float32,shape=[None,2])\n",
    "y = tf.placeholder(dtype=tf.float32,shape=[None,1])\n",
    "\n",
    "# 定义隐含层1\n",
    "h1 = tf.Variable(dtype=tf.float32,initial_value=tf.truncated_normal(shape=[2,3]))\n",
    "h2 = tf.Variable(dtype=tf.float32,initial_value=tf.truncated_normal(shape=[3,1]))\n",
    "# 定义偏置\n",
    "b1 = tf.Variable(dtype=tf.float32,initial_value=tf.zeros(shape=[3]))\n",
    "b2 = tf.Variable(dtype=tf.float32,initial_value=tf.zeros(shape=[1]))\n",
    "\n",
    "# 定义网络模型\n",
    "layer_1 = tf.nn.relu(tf.matmul(x,h1)+b1)\n",
    "pred = tf.nn.sigmoid(tf.matmul(layer_1,h2)+b2)\n",
    "cost = tf.reduce_mean(tf.square(y-pred))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = [[0,0],[0,1],[1,0],[1,1]]\n",
    "Y = [[0],[1],[1],[0]]\n",
    "X = np.array(X).astype(np.float32)\n",
    "Y = np.array(Y).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.9104259e-04]\n",
      " [9.9940002e-01]\n",
      " [9.9880183e-01]\n",
      " [6.0765416e-04]]\n"
     ]
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(10000):\n",
    "    sess.run(optimizer,feed_dict={x:X,y:Y})\n",
    "print(sess.run(pred,feed_dict={x:X}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 使用全连接网络对图片分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting data/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/mnist/t10k-labels-idx1-ubyte.gz\n",
      "epochs: 1 loss: 31.54041914766484 acc: 0.9218\n",
      "epochs: 2 loss: 5.803514355055312 acc: 0.938\n",
      "epochs: 3 loss: 3.1674637403753776 acc: 0.9478\n",
      "epochs: 4 loss: 2.0671564910447584 acc: 0.9488\n",
      "epochs: 5 loss: 1.6037047074092095 acc: 0.9563\n",
      "epochs: 6 loss: 1.4405812888084677 acc: 0.9478\n",
      "epochs: 7 loss: 1.2604456870241894 acc: 0.9578\n",
      "epochs: 8 loss: 1.0620960363571688 acc: 0.955\n",
      "epochs: 9 loss: 0.9612375956136133 acc: 0.9543\n",
      "epochs: 10 loss: 0.9075811765061731 acc: 0.9583\n",
      "epochs: 11 loss: 0.7633365943931096 acc: 0.9547\n",
      "epochs: 12 loss: 0.5869159922126443 acc: 0.9598\n",
      "epochs: 13 loss: 0.4966547162856433 acc: 0.9587\n",
      "epochs: 14 loss: 0.46215647156189715 acc: 0.9616\n",
      "epochs: 15 loss: 0.4761607729830023 acc: 0.9573\n",
      "epochs: 16 loss: 0.35861462562042923 acc: 0.9583\n",
      "epochs: 17 loss: 0.30204927054404107 acc: 0.9596\n",
      "epochs: 18 loss: 0.2515932040631139 acc: 0.9572\n",
      "epochs: 19 loss: 0.274995706463521 acc: 0.9574\n",
      "epochs: 20 loss: 0.17308197505943929 acc: 0.9565\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"data/mnist/\",one_hot = True)\n",
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(dtype=tf.float32,shape=[None,784])\n",
    "y = tf.placeholder(dtype=tf.float32,shape=[None,10])\n",
    "\n",
    "h1 = tf.Variable(dtype=tf.float32,initial_value=tf.truncated_normal(shape=[784,256]))\n",
    "b1 = tf.Variable(dtype=tf.float32,initial_value=tf.zeros(shape=[256]))\n",
    "\n",
    "h2 = tf.Variable(dtype=tf.float32,initial_value=tf.truncated_normal(shape=[256,256]))\n",
    "b2 = tf.Variable(dtype=tf.float32,initial_value=tf.zeros(shape=[256]))\n",
    "\n",
    "h_out = tf.Variable(dtype=tf.float32,initial_value=tf.truncated_normal(shape=[256,10]))\n",
    "b_out = tf.Variable(dtype=tf.float32,initial_value=tf.zeros(shape=[10]))\n",
    "\n",
    "layer_1 = tf.nn.relu(tf.matmul(x,h1)+b1)\n",
    "layer_2 = tf.nn.relu(tf.matmul(layer_1,h2)+b2)\n",
    "layer_out = tf.matmul(layer_2,h_out)+b_out\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=layer_out,labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "train_epochs = 20\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(train_epochs):\n",
    "        avg_cost = 0.0\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        for j in range(total_batch):\n",
    "            batch_x,batch_y = mnist.train.next_batch(batch_size)\n",
    "            _,loss = sess.run([optimizer,cost],feed_dict={x:batch_x,y:batch_y})\n",
    "            avg_cost = avg_cost+loss/total_batch\n",
    "        if (i+1)%display_step==0:\n",
    "            # 如果两者最大值索引相等,那么就会该位置就会变成True,否则变成False\n",
    "            correct_prediction = tf.equal(tf.argmax(layer_out,axis=1),tf.argmax(y,axis=1))\n",
    "            acc = tf.reduce_mean(tf.cast(correct_prediction,dtype=tf.float32))\n",
    "            accuracy = sess.run(acc,feed_dict={x:mnist.test.images,y:mnist.test.labels})\n",
    "            print('epochs:',i+1,'loss:',avg_cost,'acc:',accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 正则化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所谓的正则化,其实就是在神经网络计算损失值的过程中,在损失后面再加一项.随着模型复杂度增加,那么正则化损失也会增加,这样就能防止过拟合.\n",
    "+ $L1$损失:所有学习参数 $w$ 的绝对值的和.\n",
    "+ $L2$损失:所欲学习参数 $w$ 的平方和然后就平方根\n",
    "\n",
    "```python\n",
    "Tensorflow 中 L2 正则化函数为:\n",
    "tf.nn.l2_loss(w,name=None)\n",
    "\n",
    "Tensorflow 中没有现成的 L1 正则化函数,需要自己组合\n",
    "tf.reduce_sum(tf.abs(w))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting data/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/mnist/t10k-labels-idx1-ubyte.gz\n",
      "epochs: 1 loss: 107.72825730757276 acc: 0.926\n",
      "epochs: 2 loss: 60.60393948641685 acc: 0.9409\n",
      "epochs: 3 loss: 44.68430514248934 acc: 0.9481\n",
      "epochs: 4 loss: 32.92696786360306 acc: 0.946\n",
      "epochs: 5 loss: 23.92089685613461 acc: 0.9475\n",
      "epochs: 6 loss: 16.8419449892911 acc: 0.9514\n",
      "epochs: 7 loss: 11.463425773273814 acc: 0.952\n",
      "epochs: 8 loss: 7.399854530854652 acc: 0.9484\n",
      "epochs: 9 loss: 4.456128301620484 acc: 0.9447\n",
      "epochs: 10 loss: 2.5142341375350945 acc: 0.9491\n",
      "epochs: 11 loss: 1.3514582600376828 acc: 0.9578\n",
      "epochs: 12 loss: 0.7686492352052176 acc: 0.9622\n",
      "epochs: 13 loss: 0.492222175056284 acc: 0.9578\n",
      "epochs: 14 loss: 0.38345455386421945 acc: 0.9491\n",
      "epochs: 15 loss: 0.34847966836257427 acc: 0.9573\n",
      "epochs: 16 loss: 0.33561972964893716 acc: 0.9533\n",
      "epochs: 17 loss: 0.33416108854792376 acc: 0.9515\n",
      "epochs: 18 loss: 0.33401638014750057 acc: 0.9427\n",
      "epochs: 19 loss: 0.33367943351919027 acc: 0.9422\n",
      "epochs: 20 loss: 0.3249709372086961 acc: 0.946\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"data/mnist/\",one_hot = True)\n",
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(dtype=tf.float32,shape=[None,784])\n",
    "y = tf.placeholder(dtype=tf.float32,shape=[None,10])\n",
    "\n",
    "h1 = tf.Variable(dtype=tf.float32,initial_value=tf.truncated_normal(shape=[784,256]))\n",
    "b1 = tf.Variable(dtype=tf.float32,initial_value=tf.zeros(shape=[256]))\n",
    "\n",
    "h2 = tf.Variable(dtype=tf.float32,initial_value=tf.truncated_normal(shape=[256,256]))\n",
    "b2 = tf.Variable(dtype=tf.float32,initial_value=tf.zeros(shape=[256]))\n",
    "\n",
    "h_out = tf.Variable(dtype=tf.float32,initial_value=tf.truncated_normal(shape=[256,10]))\n",
    "b_out = tf.Variable(dtype=tf.float32,initial_value=tf.zeros(shape=[10]))\n",
    "\n",
    "layer_1 = tf.nn.relu(tf.matmul(x,h1)+b1)\n",
    "layer_2 = tf.nn.relu(tf.matmul(layer_1,h2)+b2)\n",
    "layer_out = tf.matmul(layer_2,h_out)+b_out\n",
    "\n",
    "# 在这个数据集中,过拟合现象不严重,所以加入之后对效果影响不大\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=layer_out,labels=y))\n",
    "cost = cost + tf.nn.l2_loss(h1)*0.001+tf.nn.l2_loss(h2)*0.001+tf.nn.l2_loss(h_out)*0.001\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "train_epochs = 20\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(train_epochs):\n",
    "        avg_cost = 0.0\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        for j in range(total_batch):\n",
    "            batch_x,batch_y = mnist.train.next_batch(batch_size)\n",
    "            _,loss = sess.run([optimizer,cost],feed_dict={x:batch_x,y:batch_y})\n",
    "            avg_cost = avg_cost+loss/total_batch\n",
    "        if (i+1)%display_step==0:\n",
    "            # 如果两者最大值索引相等,那么就会该位置就会变成True,否则变成False\n",
    "            correct_prediction = tf.equal(tf.argmax(layer_out,axis=1),tf.argmax(y,axis=1))\n",
    "            acc = tf.reduce_mean(tf.cast(correct_prediction,dtype=tf.float32))\n",
    "            accuracy = sess.run(acc,feed_dict={x:mnist.test.images,y:mnist.test.labels})\n",
    "            print('epochs:',i+1,'loss:',avg_cost,'acc:',accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
